{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-07T01:53:17.115872300Z",
     "start_time": "2023-11-07T01:53:16.823626300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(   floor_area_sqm  lease_commence_date  latitude   longitude  subzone  \\\n 0            82.0                 1975  1.341005  103.854412       76   \n 1            92.0                 2014  1.393338  103.914701       97   \n 2            90.0                 2003  1.321499  103.738982      121   \n 3            68.0                 1976  1.302113  103.909481       81   \n 4           110.0                 2002  1.389456  103.772226       43   \n \n    rent_approval_year  rent_approval_month  coe_price  Year  Month  ...  \\\n 0                2022                    1  65851.375  2022      1  ...   \n 1                2021                    2  44871.000  2021      2  ...   \n 2                2021                    8  51997.375  2021      8  ...   \n 3                2021                    7  50467.000  2021      7  ...   \n 4                2022                    2  71757.125  2022      2  ...   \n \n    planning_area_queenstown  planning_area_rochor  planning_area_sembawang  \\\n 0                         0                     0                        0   \n 1                         0                     0                        0   \n 2                         0                     0                        0   \n 3                         0                     0                        0   \n 4                         0                     0                        0   \n \n    planning_area_sengkang  planning_area_serangoon  planning_area_tampines  \\\n 0                       0                        0                       0   \n 1                       0                        0                       0   \n 2                       0                        0                       0   \n 3                       0                        0                       0   \n 4                       0                        0                       0   \n \n    planning_area_toa_payoh  planning_area_woodlands  planning_area_yishun  \\\n 0                        1                        0                     0   \n 1                        0                        0                     0   \n 2                        0                        0                     0   \n 3                        0                        0                     0   \n 4                        0                        0                     0   \n \n    predicted_monthly_rent  \n 0             2264.302490  \n 1             2128.982910  \n 2             2232.974609  \n 3             2074.701416  \n 4             2340.175293  \n \n [5 rows x 70 columns],\n    floor_area_sqm  lease_commence_date  latitude   longitude  subzone  \\\n 0           121.0                 1984  1.358411  103.891722       77   \n 1           100.0                 1999  1.446343  103.820817      102   \n 2            91.0                 1980  1.305719  103.762168       35   \n 3            74.0                 1986  1.344832  103.730778      150   \n 4           121.0                 1983  1.345437  103.735241      150   \n \n    rent_approval_year  rent_approval_month   coe_price  Year  Month  ...  \\\n 0                2023                    1   92845.000  2023      1  ...   \n 1                2022                    9   92942.625  2022      9  ...   \n 2                2023                    7  104442.375  2023      7  ...   \n 3                2021                    8   51997.375  2021      8  ...   \n 4                2022                    3   79016.000  2022      3  ...   \n \n    planning_area_punggol  planning_area_queenstown  planning_area_rochor  \\\n 0                      0                         0                     0   \n 1                      0                         0                     0   \n 2                      0                         0                     0   \n 3                      0                         0                     0   \n 4                      0                         0                     0   \n \n    planning_area_sembawang  planning_area_sengkang  planning_area_serangoon  \\\n 0                        0                       0                        0   \n 1                        1                       0                        0   \n 2                        0                       0                        0   \n 3                        0                       0                        0   \n 4                        0                       0                        0   \n \n    planning_area_tampines  planning_area_toa_payoh  planning_area_woodlands  \\\n 0                       0                        0                        0   \n 1                       0                        0                        0   \n 2                       0                        0                        0   \n 3                       0                        0                        0   \n 4                       0                        0                        0   \n \n    planning_area_yishun  \n 0                     0  \n 1                     0  \n 2                     0  \n 3                     0  \n 4                     0  \n \n [5 rows x 69 columns])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from both CSV files\n",
    "predictions_path = './Datasets/results/back_to_v1.csv'\n",
    "submission_path = './Datasets/test_set_v1.csv'\n",
    "\n",
    "# Reading the files\n",
    "predictions_df = pd.read_csv(predictions_path)\n",
    "submission_df = pd.read_csv(submission_path)\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "(predictions_df.head(), submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['flat_type', 'resale_price_index', 'month', 'average_school_rank',\n       'year'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Drop duplicates in the 'predictions' dataframe while keeping the first occurrence\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m predictions_df_unique \u001B[38;5;241m=\u001B[39m \u001B[43mpredictions_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop_duplicates\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mflat_type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfloor_area_sqm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlease_commence_date\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlatitude\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlongitude\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43myear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmonth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresale_price_index\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maverage_school_rank\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[0;32m      5\u001B[0m \u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfirst\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# Merge again with the deduplicated 'predictions' dataframe\u001B[39;00m\n\u001B[0;32m      8\u001B[0m merged_df_unique \u001B[38;5;241m=\u001B[39m submission_df\u001B[38;5;241m.\u001B[39mmerge(predictions_df_unique, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m, on\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflat_type\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfloor_area_sqm\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlease_commence_date\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatitude\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlongitude\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124myear\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmonth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresale_price_index\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124maverage_school_rank\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     11\u001B[0m ])\n",
      "File \u001B[1;32m~\\.conda\\envs\\project-tpot-38\\lib\\site-packages\\pandas\\core\\frame.py:6522\u001B[0m, in \u001B[0;36mDataFrame.drop_duplicates\u001B[1;34m(self, subset, keep, inplace, ignore_index)\u001B[0m\n\u001B[0;32m   6519\u001B[0m inplace \u001B[38;5;241m=\u001B[39m validate_bool_kwarg(inplace, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minplace\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6520\u001B[0m ignore_index \u001B[38;5;241m=\u001B[39m validate_bool_kwarg(ignore_index, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore_index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 6522\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mduplicated\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[0;32m   6523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ignore_index:\n\u001B[0;32m   6524\u001B[0m     result\u001B[38;5;241m.\u001B[39mindex \u001B[38;5;241m=\u001B[39m default_index(\u001B[38;5;28mlen\u001B[39m(result))\n",
      "File \u001B[1;32m~\\.conda\\envs\\project-tpot-38\\lib\\site-packages\\pandas\\core\\frame.py:6654\u001B[0m, in \u001B[0;36mDataFrame.duplicated\u001B[1;34m(self, subset, keep)\u001B[0m\n\u001B[0;32m   6652\u001B[0m diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(subset) \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns)\n\u001B[0;32m   6653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m diff:\n\u001B[1;32m-> 6654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(Index(diff))\n\u001B[0;32m   6656\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subset) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique:\n\u001B[0;32m   6657\u001B[0m     \u001B[38;5;66;03m# GH#45236 This is faster than get_group_index below\u001B[39;00m\n\u001B[0;32m   6658\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m[subset[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39mduplicated(keep)\n",
      "\u001B[1;31mKeyError\u001B[0m: Index(['flat_type', 'resale_price_index', 'month', 'average_school_rank',\n       'year'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "# Drop duplicates in the 'predictions' dataframe while keeping the first occurrence\n",
    "predictions_df_unique = predictions_df.drop_duplicates(subset=[\n",
    "    'flat_type', 'floor_area_sqm', 'lease_commence_date', 'latitude', 'longitude',\n",
    "    'year', 'month', 'resale_price_index', 'average_school_rank'\n",
    "], keep='first')\n",
    "\n",
    "# Merge again with the deduplicated 'predictions' dataframe\n",
    "merged_df_unique = submission_df.merge(predictions_df_unique, how='left', on=[\n",
    "    'flat_type', 'floor_area_sqm', 'lease_commence_date', 'latitude', 'longitude',\n",
    "    'year', 'month', 'resale_price_index', 'average_school_rank'\n",
    "])\n",
    "\n",
    "# Check the number of rows in the merged dataframe and if there are any empty values\n",
    "num_rows_merged_unique = merged_df_unique.shape[0]\n",
    "empty_values_unique = merged_df_unique.isnull().sum()\n",
    "\n",
    "merged_df_unique.to_csv('./Datasets/results/submission predictions 2023-11-12-test set v1-filled.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T01:53:31.159568400Z",
     "start_time": "2023-11-07T01:53:31.020048700Z"
    }
   },
   "id": "513bc23a648b1177"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Drop duplicates in the 'predictions' dataframe while keeping the first occurrence\n",
    "predictions_df_unique = predictions_df.drop_duplicates(subset=[\n",
    "    'floor_area_sqm', 'lease_commence_date', 'latitude', 'longitude', 'subzone', 'rent_approval_year',\n",
    "    'rent_approval_month', 'coe_price', 'Year', 'Month', 'Stock_Price', 'mrt_nearest_distance', 'mrt_count_within_1km',\n",
    "    'mall_nearest_distance', 'mall_count_within_1km', 'mrt_planned_nearest_distance', 'mrt_planned_count_within_1km',\n",
    "    'flat_type_ordinal', 'distance_to_centroid_marina_bay'\n",
    "], keep='first')\n",
    "\n",
    "# Merge again with the deduplicated 'predictions' dataframe\n",
    "merged_df_unique = submission_df.merge(predictions_df_unique, how='left', on=[\n",
    "    'floor_area_sqm', 'lease_commence_date', 'latitude', 'longitude', 'subzone', 'rent_approval_year',\n",
    "    'rent_approval_month', 'coe_price', 'Year', 'Month', 'Stock_Price', 'mrt_nearest_distance', 'mrt_count_within_1km',\n",
    "    'mall_nearest_distance', 'mall_count_within_1km', 'mrt_planned_nearest_distance', 'mrt_planned_count_within_1km',\n",
    "    'flat_type_ordinal', 'distance_to_centroid_marina_bay'\n",
    "])\n",
    "\n",
    "# Check the number of rows in the merged dataframe and if there are any empty values\n",
    "num_rows_merged_unique = merged_df_unique.shape[0]\n",
    "empty_values_unique = merged_df_unique.isnull().sum()\n",
    "\n",
    "merged_df_unique.to_csv('./Datasets/results/submission predictions 2023-11-12-test set v1-filled.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T01:57:07.019613700Z",
     "start_time": "2023-11-07T01:57:05.324880900Z"
    }
   },
   "id": "b5c106148900b653"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
